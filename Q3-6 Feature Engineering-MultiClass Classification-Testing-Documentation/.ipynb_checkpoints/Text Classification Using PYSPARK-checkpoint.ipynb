{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT CLASSIFICATION USING PYSPARK AND MLLIB\n",
    "\n",
    "The goal of Lab 3 is the classification of ARTICLES downloaded from NYT into a fixed number of predefined categories. In this notebook, we walk through an example of text classifcation using Spark machine learning algorithms. We will  classify the documents into 4 categories -Multi Class classification.\n",
    "Steps:\n",
    "\n",
    "## Build a data pipeline using Downloaded Data from  NY Times articles using the APIs provided by the data sources.  \n",
    "#####       a. Create PYSAPRK DataFrames from the downloaded data \n",
    "#####      b. Split the Learning Dataset into training and test data \n",
    "#####      c. Extract features that will determine the class or category of the article {politics, sports,\n",
    "#####      business, arts}\n",
    "## Build a model for classification using Logistic Regression, Naive Bayes and Random Foresy classification algorithms on Learning Dataset.\n",
    "## Assess the accuracy of MODEL using the UNKNOWN data \n",
    "## Compare the classification accuracy of at least two well-known classification algorithms,  for a given text data set.\n",
    "\n",
    "### Create DATA FRAME in PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.chdir('/Users/vikrant/data/')\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, StopWordsRemover, IDF, Tokenizer\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "from pyspark.mllib.linalg import Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Downloaded Data Files ; Create Learning DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpath = '/Users/vikrant/data/NYT/*'\n",
    "NYTRawData = sc.wholeTextFiles(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"The number of documents read in is \" + NYTRawData.count() + \".\")\n",
    "NYTRawData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create UNKNOWN Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirpathUN = '/Users/vikrant/data/UnknownData/*'\n",
    "NYTRawDataUNKNOWN = sc.wholeTextFiles(dirpathUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"The number of documents read in is \" + NYTRawData.count() + \".\")\n",
    "NYTRawDataUNKNOWN.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Sample Data from Learning Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/Users/vikrant/data/NYT/business/5a96061810f40f00018c366b',\n",
       "  'In N.R.A. Fight, Delta Finds There Is No Neutral Ground\\nATLANTA — Delta Air Lines, one of Georgia’s largest private-sector employers, is among the glossiest corporate jewels in the state, contributing billions of dollars a year to the economy. Its hundreds of daily flights in and out of Atlanta’s airport are the main reason Georgia’s capital can brag, with justification, that it is a truly international city.\\n“Delta is the Atlanta international airport, and our airport is, you know, the fuel that generates our commercial community,” said Sam Massell, the city’s former mayor.\\nBut prestige, boosterism and corporate coddling — all cherished concepts in Georgia — took a back seat this week to the national debate over gun control. In the wake of the Florida school shooting, the airline announced it was ending a promotional discount with the National Rifle Association, and suddenly found itself in the rare position of being openly dressed down — and potentially punished — by Republicans who control the statehouse.\\nLt. Gov. Casey Cagle of Georgia, a Republican who presides over the State Senate and has received an A-plus grade from the N.R.A., joined other conservative lawmakers this week in threatening to remove a $50 million sales tax exemption on jet fuel that some hoped would encourage Delta to open even more routes — and help Atlanta attract even more national and international companies.\\nThe conservative backlash highlighted the challenge confronting corporations around the country that are struggling to cater to both ends of America’s increasingly distant political and cultural poles.\\nAs pressure from social media and advocacy groups has intensified, and calls for boycotts mount, more than a dozen companies have severed business ties with the N.R.A. since the massacre in Parkland, Fla. Just as quickly, a counteroffensive arose from gun supporters excoriating the companies for their stance, forcing business leaders to navigate the treacherous ground where social responsibility, ideology and financial impact converge.\\nDelta did not respond on Tuesday to Mr. Cagle’s threat or amplify its stance regarding the N.R.A. In a statement over the weekend, the company said its decision to stop offering discounted fares to the N.R.A. “reflects the airline’s neutral status in the current national debate over gun control amid recent school shootings.”\\nAs of Tuesday afternoon, the jet-fuel tax break, while opposed by Mr. Cagle and some other conservative Republicans, had not yet been stripped out of a broader Senate tax bill.\\nDelta chose to end special discounts, but FedEx took a different approach, one that highlighted the delicate balancing act. In a statement Monday, FedEx said it disagreed with the N.R.A.’s stance on civilian access to assault rifles but would continue to offer discounts of up to 26 percent to the group’s members.\\n“We are very clear that, when we set pricing strategy or look to adjust pricing, it is not based on political positions or points of view,” Patrick Fitzgerald, the company’s senior vice president, integrated marketing and communications, said in an interview on Tuesday. “But we do have a very clear corporate position in terms of gun safety and school safety.”\\nIn Georgia, the debate has been surprisingly fiery, even in a state long defined by tensions between the liberal metropolis and conservative countryside, and between the values of global corporate culture and those of Southern Republicans.\\n“Corporations cannot attack conservatives and expect us not to fight back,” Mr. Cagle, a leading G.O.P. candidate for governor, wrote in a tweet Monday, in which he announced that he would “kill any tax legislation” that benefited Delta unless it changed its position.\\nState Senator Josh McKoon said in an interview Tuesday that he was put off by Delta’s assertion that it was trying to remain neutral on the guns issue, when it had taken positions on other social topics in the past.\\n“It just came off as very disingenuous,” Mr. McKoon said of Delta’s statement.\\nReferring to Mr. Cagle’s pushback, Mr. McKoon said, “I think he captured the sentiment and the feeling of a lot of Georgians,” who, he said, were frustrated “with Delta weighing in on an issue that has nothing to do with the topic of transportation, for sure.”\\nBut Mr. Massell, the former mayor who is president of the Buckhead Coalition, an influential Atlanta business and civic group, called the entire debate “embarrassing.” He said that he feared the threat against Delta would scare away Amazon, the online retail giant that has listed Atlanta among the finalists for its second headquarters.\\n“I don’t believe in blackmail, and I’m sorry to use such a dirty word, but that’s almost what it tastes like,” said Mr. Massell, a Democrat who served as mayor from 1970 to 1974. “That’s terrible. That’s not Georgia’s image. That’s backwoods stuff that doesn’t belong at all.”\\nThe story of Delta and the story of Atlanta have been deeply intertwined for decades. The company was founded in Louisiana in the 1920s; it focused, in the earliest days, on crop dusting, in an effort to end the boll weevil infestation that had ruined many Southern cotton crops. The company moved to Atlanta in 1941.\\nIn subsequent decades, the city, which was founded as a railroad hub, invested heavily in its airport, and pushed a message that it was more socially tolerant than other Southern cities like Birmingham. It was a winning combination. Today, Hartsfield-Jackson Atlanta International Airport is the busiest in the world, and Delta employs more than 33,000 Georgia residents.\\nIts current problem with the legislature has prompted leaders in other states to woo Delta via Twitter. “You know, in mathematics, Delta represents the change in something,” wrote Randall Woodfin, the mayor of Birmingham. He added, “Let’s chat.”\\nMichael Gordon, a professor at the University of Michigan’s Ross School of Business and faculty director of the Center for Social Impact, said in an interview that “Delta has every right to tell legislators, ‘We’re not of a mind to do your bidding.’ They could easily pack their bags and move away from Atlanta and go to Dallas.”\\nBut it seemed unlikely that the airline would move. In 2016, the company signed an airport lease with the city that would keep its headquarters in Atlanta through 2036.\\n“Atlanta and Georgia and the business community usually try to work together and Delta is a huge employer in this state,” said another former Atlanta mayor, Shirley Franklin. “So the relationship is damaged, if nothing else.”\\nA broader concern, shared by some liberals, conservatives and members of the Georgia business community, is that gun control may now join other hot-button cultural topics that may damage the state’s reputation among national and global corporations that do not adhere to the same conservative Southern values as the state legislature.\\nIn the last few years, the legislature has taken up a number of prominent bills that critics say would allow for discrimination against lesbian, gay, bisexual and transgender people. Gov. Nathan Deal vetoed one of them, a so-called religious liberty bill, in 2016, after some of the state’s most prestigious and powerful companies — including Delta, Home Depot and Coca-Cola — openly opposed the measure.\\nMr. Deal, a Republican, will soon leave office because of term limits. Mr. Cagle, a leading candidate to replace him, is among a number of Republican hopefuls who say they will continue to support the legislation, which would have strengthened legal protection for opponents of same-sex marriage.\\nMr. McKoon, a Republican who is leaving the upper chamber to run for secretary of state, said that he had long opposed the jet-fuel tax break on the grounds that it seemed like a handout for a politically connected industry.\\nMr. McKoon was a vocal supporter of the 2016 religious liberty bill that Mr. Deal vetoed. He said that when that legislation failed, he issued a warning, saying that liberals would continue pressuring companies to embrace progressive social positions.\\nHe warned, he said, that “the next logical step would be to attack gun rights. And I think we are seeing the beginning of that.”\\n')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTRawData.takeSample(False,1, seed = 231279)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Sample Data from UNKNOWN Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/Users/vikrant/data/UnknownData/business/5ae88376068401528a2aba41',\n",
       "  'Legendary U.S. Guitar-Maker Gibson Files for Bankruptcy\\n(Reuters) - Gibson Brands Inc, the maker of guitars played by the likes of B.B. King and Elvis Presley, filed for Chapter 11 bankruptcy protection on Tuesday with a plan to reorganize its musical instrument business under the new ownership of its lenders.\\nNashville-based Gibson, whose legendary brands include Les Paul and SG, has been suffering under $500 million in debt linked to the acquisition of its consumer electronics business overseas, where sales have been in sharp decline.\\nIn a filing in U.S. Bankruptcy Court in Delaware, Gibson said the overseas consumer electronics business will be wound down, allowing it to re-focus on its core guitar-making and audio businesses.\\nThe audio business includes KRK, Cerwin Vega and Stanton headphones, loud speakers and turntables for amateur and professional musicians and sound engineers. \\n\"This process will be virtually invisible to customers, all of whom can continue to rely on Gibson to provide unparalleled products and customer service,\" Chief Executive Henry Juszkiewicz said in a press release.\\nJuszkiewicz acquired Gibson in 1986.\\nUnder a restructuring pact, senior lenders including Silver Point Capital, Melody Capital Partners LP and funds affiliated with KKR Credit Advisors will exchange debt for equity ownership in the reorganized company.\\nGibson said sales of its electric guitars grew 10.5 percent to $122 million in the 12 months through January from a year earlier.\\nGibson, founded in 1894, makes its electric guitars in U.S. factories in Nashville and Memphis, Tennessee and its acoustic guitars in Bozeman, Montana. It sells more than 170,000 guitars annually in more than 80 countries.\\nIt bought the Hong Kong-based consumer electronics arm from Philips in 2014, and started to wind down the unsuccessful business -- including formal liquidation proceedings in Hong Kong, the United Kingdom and six European countries -- on April 30, according to court papers.\\nGibson has secured $135 million in debtor-in-possession financing to fund its operations during the Chapter 11 proceedings. It plans to exit bankruptcy on Sept. 24.\\n (Reporting by Tracy Rucinski in Chicago; Editing by Susan Thomas)\\n')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYTRawDataUNKNOWN.takeSample(False,1, seed = 231279)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = NYTRawData.map(lambda x:x[0]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter RDD to Capture Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = NYTRawData.map(lambda x:x[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "textUN = NYTRawDataUNKNOWN.map(lambda x:x[1]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to DataFrame\n",
    "##### Learning Dataframe = \"df\"\n",
    "##### Unknown Dataframe =\" dfUN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "\n",
    "#here you are going to create a function\n",
    "def f(x):\n",
    "    d = {}\n",
    "    for i in range(len(x)):\n",
    "        d[str(i)] = x[i]\n",
    "    return d\n",
    "\n",
    "#Now populate that\n",
    "df = NYTRawData.map(lambda x: Row(**f(x))).toDF()#.withColumn(\"Label\",lit(\"Politics\"))\n",
    "dfUN = NYTRawDataUNKNOWN.map(lambda x: Row(**f(x))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfUN.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Learning Dataset for Modeling using Classification Models\n",
    "###### Split Columns to get Category of each Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "split_col = split(df['0'], '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('NAME6', split_col.getItem(5))\n",
    "df = df.withColumn('NAME7', split_col.getItem(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+\n",
      "|                   0|                   1|NAME6|               NAME7|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|file:/Users/vikra...|R. Kelly Faces a ...| arts|5ae88aee068401528...|\n",
      "|file:/Users/vikra...|Pop, Rock and Jaz...| arts|5a4f82147c459f29e...|\n",
      "|file:/Users/vikra...|‘Così’ at the Met...| arts|5aac272d068401528...|\n",
      "|file:/Users/vikra...|‘Breaking Ice’ Ma...| arts|5a4f5ac57c459f29e...|\n",
      "|file:/Users/vikra...|8 Classical Music...| arts|5acfc8d8068401528...|\n",
      "|file:/Users/vikra...|8 Classical Music...| arts|5aaaded9068401528...|\n",
      "|file:/Users/vikra...|SZA Almost Quit M...| arts|5a6798f610f40f000...|\n",
      "|file:/Users/vikra...|Luigi Nono’s Hars...| arts|5a905b9a10f40f000...|\n",
      "|file:/Users/vikra...|14 Pop, Rock and ...| arts|5acfc8da068401528...|\n",
      "|file:/Users/vikra...|Yannick, Sooner: ...| arts|5a87286d10f40f000...|\n",
      "|file:/Users/vikra...|Seeking Orchestra...| arts|5ad74f68068401528...|\n",
      "|file:/Users/vikra...|Live Nation Rules...| arts|5ac0e5e8068401528...|\n",
      "|file:/Users/vikra...|The Playlist: Nic...| arts|5ad0f6ce068401528...|\n",
      "|file:/Users/vikra...|7 Classical Music...| arts|5aeb7857068401528...|\n",
      "|file:/Users/vikra...|Review: ‘Written ...| arts|5a80bbfb10f40f000...|\n",
      "|file:/Users/vikra...|Logic, XXXTentaci...| arts|5ac7e40a068401528...|\n",
      "|file:/Users/vikra...|A Long-Lost Compo...| arts|5a6f39d510f40f000...|\n",
      "|file:/Users/vikra...|14 Pop, Rock and ...| arts|5a8f3d7910f40f000...|\n",
      "|file:/Users/vikra...|Lucy Dacus, Socce...| arts|5a998a545d97b3000...|\n",
      "|file:/Users/vikra...|Through Opera, De...| arts|5acddcad068401528...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: string (nullable = true)\n",
      " |-- 1: string (nullable = true)\n",
      " |-- NAME6: string (nullable = true)\n",
      " |-- NAME7: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                   1|NAME6|\n",
      "+--------------------+-----+\n",
      "|R. Kelly Faces a ...| arts|\n",
      "|Pop, Rock and Jaz...| arts|\n",
      "|‘Così’ at the Met...| arts|\n",
      "|‘Breaking Ice’ Ma...| arts|\n",
      "|8 Classical Music...| arts|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- 1: string (nullable = true)\n",
      " |-- NAME6: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['0', 'NAME7']#, 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "df = df.select([column for column in df.columns if column not in drop_list])\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Article|Category|\n",
      "+--------------------+--------+\n",
      "|R. Kelly Faces a ...|    arts|\n",
      "|Pop, Rock and Jaz...|    arts|\n",
      "|‘Così’ at the Met...|    arts|\n",
      "|‘Breaking Ice’ Ma...|    arts|\n",
      "|8 Classical Music...|    arts|\n",
      "|8 Classical Music...|    arts|\n",
      "|SZA Almost Quit M...|    arts|\n",
      "|Luigi Nono’s Hars...|    arts|\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|Yannick, Sooner: ...|    arts|\n",
      "|Seeking Orchestra...|    arts|\n",
      "|Live Nation Rules...|    arts|\n",
      "|The Playlist: Nic...|    arts|\n",
      "|7 Classical Music...|    arts|\n",
      "|Review: ‘Written ...|    arts|\n",
      "|Logic, XXXTentaci...|    arts|\n",
      "|A Long-Lost Compo...|    arts|\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|Lucy Dacus, Socce...|    arts|\n",
      "|Through Opera, De...|    arts|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import col\n",
    "df = df.select(col(\"1\").alias(\"Article\"), col(\"NAME6\").alias(\"Category\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning Data Set \n",
    "\n",
    "##### (Collection of approx 589 articles in 4 categories from NYT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Category|count|\n",
      "+--------+-----+\n",
      "|politics|  188|\n",
      "|  sports|  155|\n",
      "|    arts|  151|\n",
      "|business|   95|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.groupBy(\"Category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare UNKNOWN DataSet for Testing using CLASSIFICATION MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 0: string (nullable = true)\n",
      " |-- 1: string (nullable = true)\n",
      " |-- NAME6: string (nullable = true)\n",
      " |-- NAME7: string (nullable = true)\n",
      "\n",
      "+--------+-----+\n",
      "|Category|count|\n",
      "+--------+-----+\n",
      "|  sports|   15|\n",
      "|business|   12|\n",
      "|politics|   12|\n",
      "|    arts|   10|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_col = split(dfUN['0'], '/')\n",
    "dfUN = dfUN.withColumn('NAME6', split_col.getItem(5))\n",
    "dfUN = dfUN.withColumn('NAME7', split_col.getItem(6))\n",
    "dfUN.printSchema()\n",
    "drop_list = ['0', 'NAME7']#, 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']\n",
    "dfUN = dfUN.select([column for column in dfUN.columns if column not in drop_list])\n",
    "#dfUN.show(5)\n",
    "dfUN = dfUN.select(col(\"1\").alias(\"Article\"), col(\"NAME6\").alias(\"Category\"))\n",
    "#dfUN.show()\n",
    "from pyspark.sql.functions import col\n",
    "dfUN.groupBy(\"Category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIvide  Learning Data Set into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 472\n",
      "Test Dataset Count: 117\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2], seed = 231279)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Article|Category|\n",
      "+--------------------+--------+\n",
      "|10 Treasures, Une...|    arts|\n",
      "|100 Years After D...|    arts|\n",
      "|13 Pop, Rock and ...|    arts|\n",
      "|13 Pop, Rock and ...|    arts|\n",
      "|13 Pop, Rock and ...|    arts|\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|15 Pop, Rock and ...|    arts|\n",
      "|2018 N.F.L. Draft...|  sports|\n",
      "|28 Years After Hi...|    arts|\n",
      "|5 ‘Schoolhouse Ro...|    arts|\n",
      "|6 Classical Music...|    arts|\n",
      "|6 Classical Music...|    arts|\n",
      "|6 Classical Music...|    arts|\n",
      "|6 Classical Music...|    arts|\n",
      "|7 Classical Music...|    arts|\n",
      "|7 Classical Music...|    arts|\n",
      "|8 Classical Music...|    arts|\n",
      "|8 Classical Music...|    arts|\n",
      "|8 Classical Music...|    arts|\n",
      "|A Battle Over Tra...|business|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Article|Category|\n",
      "+--------------------+--------+\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|14 Pop, Rock and ...|    arts|\n",
      "|6 Classical Music...|    arts|\n",
      "|7 Classical Music...|    arts|\n",
      "|7 Classical Music...|    arts|\n",
      "|A Tone Parallel t...|    arts|\n",
      "|Air France Cuts B...|business|\n",
      "|Athletics-AIU Con...|  sports|\n",
      "|Baffert Talks Der...|  sports|\n",
      "|Classical Music i...|    arts|\n",
      "|Classical Music i...|    arts|\n",
      "|Clayton Homes Mim...|business|\n",
      "|Cleveland Conquer...|    arts|\n",
      "|Column: Payne's I...|  sports|\n",
      "|Column: US League...|  sports|\n",
      "|ESPN Tries to Get...|  sports|\n",
      "|Elliott Says Back...|business|\n",
      "|FIFA Bans Brazili...|  sports|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISPLAY UNknown DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Article|Category|\n",
      "+--------------------+--------+\n",
      "|Avicii: Overexpos...|    arts|\n",
      "|‘Bobby Tarantino ...|    arts|\n",
      "|Listen to This Aw...|    arts|\n",
      "|Beyoncé and Kendr...|    arts|\n",
      "|Abba Records New ...|    arts|\n",
      "|In Defense of Sou...|    arts|\n",
      "|Hear What Music W...|    arts|\n",
      "|Berklee College E...|    arts|\n",
      "|Justin Timberlake...|    arts|\n",
      "|The Complex Inter...|    arts|\n",
      "|Russia's NLMK Say...|business|\n",
      "|U.S. Factory Orde...|business|\n",
      "|Legendary U.S. Gu...|business|\n",
      "|New Recycling Ser...|business|\n",
      "|Permira to Buy Ba...|business|\n",
      "|China Asks U.S. t...|business|\n",
      "|Leader of Latino ...|business|\n",
      "|OC Oerlikon Prepa...|business|\n",
      "|Kellogg Tops Prof...|business|\n",
      "|Why BlackRock’s M...|business|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfUN.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification  Using Logistic Regression\n",
    "**LogisticRegression** is a method used to predict a binary response. The current implementation of logistic regression in spark.ml only supports binary classes. Support for multiclass regression will be added in the future.\n",
    "### Train the Learning Dataset (TRAIN And TEst)\n",
    "### Build Pipeline using TF IDF \n",
    "\n",
    "In machine learning, it is common to run a sequence of algorithms to process and learn from data. Spark ML represents such a workflow as a Pipeline, which consists of a sequence of PipelineStages (Transformers and Estimators) to be run in a specific order. The pipeline we are using in this example consists of four stages: Tokenizer, StopWordsRemover, HashingTF, Inverse Document Frequency (IDF) and LogisticRegression.\n",
    "\n",
    "**Tokenizer** splits the raw text documents into words, adding a new column with words into the dataset.\n",
    "\n",
    "**StopWordsRemover** takes as input a sequence of strings and drops all the stop words from the input sequences. Stop words are words which should be excluded from the input, typically because the words appear frequently and don’t carry as much meaning. A list of stop words by default. Optionally you can provide a list of stopwords. We will just use the defualt list of stopwords.\n",
    "\n",
    "**HashingTF** takes sets of terms and converts those sets into fixed-length feature vectors. \n",
    "\n",
    "**Inverse Document Frequency (IDF)** is a numerical measure of how much information a term provides. If a term appears very often across the corpus, it means it doesn’t carry special information about a particular document. IDF down-weights terms which appear frequently in a corpus.\n",
    "\n",
    "\n",
    "\n",
    "###### Our model will make predictions and score on the test set; we then look at the top 10 predictions from the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"Article\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"Category\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, remover, hashingTF, idf, label_stringIdx, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+----------+\n",
      "|               words|            features|label|         probability|prediction|\n",
      "+--------------------+--------------------+-----+--------------------+----------+\n",
      "|[10, treasures, u...|(10000,[2,93,126,...|  2.0|[0.01011542778836...|       2.0|\n",
      "|[100, years, afte...|(10000,[32,87,90,...|  2.0|[0.00472514455689...|       2.0|\n",
      "|[13, pop, rock, a...|(10000,[26,57,69,...|  2.0|[0.00166947516238...|       2.0|\n",
      "|[13, pop, rock, a...|(10000,[31,37,62,...|  2.0|[0.00353282966956...|       2.0|\n",
      "|[13, pop, rock, a...|(10000,[57,62,122...|  2.0|[0.00358468847175...|       2.0|\n",
      "|[14, pop, rock, a...|(10000,[12,23,60,...|  2.0|[0.00248503592248...|       2.0|\n",
      "|[15, pop, rock, a...|(10000,[29,76,104...|  2.0|[2.46429226092113...|       2.0|\n",
      "|[2018, n, f, l, d...|(10000,[33,87,123...|  1.0|[0.00668749713916...|       1.0|\n",
      "|[28, years, after...|(10000,[65,104,12...|  2.0|[0.02344520328745...|       2.0|\n",
      "|[5, schoolhouse, ...|(10000,[8,15,16,1...|  2.0|[0.03499993338446...|       2.0|\n",
      "|[6, classical, mu...|(10000,[26,76,104...|  2.0|[0.00848971900653...|       2.0|\n",
      "|[6, classical, mu...|(10000,[23,69,78,...|  2.0|[0.00763274738673...|       2.0|\n",
      "|[6, classical, mu...|(10000,[90,119,15...|  2.0|[0.00883848974073...|       2.0|\n",
      "|[6, classical, mu...|(10000,[87,128,15...|  2.0|[0.00958277495979...|       2.0|\n",
      "|[7, classical, mu...|(10000,[63,65,76,...|  2.0|[0.01228674115433...|       2.0|\n",
      "|[7, classical, mu...|(10000,[1,63,65,1...|  2.0|[0.01097266761357...|       2.0|\n",
      "|[8, classical, mu...|(10000,[1,24,47,5...|  2.0|[0.00657690655947...|       2.0|\n",
      "|[8, classical, mu...|(10000,[167,210,2...|  2.0|[0.01207904792138...|       2.0|\n",
      "|[8, classical, mu...|(10000,[43,126,14...|  2.0|[0.01299970916062...|       2.0|\n",
      "|[a, battle, over,...|(10000,[1,58,63,7...|  3.0|[0.02627743161485...|       3.0|\n",
      "+--------------------+--------------------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrdata = model.transform(trainingData).select(\"words\",\"features\",\"label\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Prediction on TEST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|Category|                      features|                   probability|label|prediction|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|  sports|(10000,[32,82,126,157,161,1...|[0.40628029138195526,0.5298...|  1.0|       1.0|\n",
      "|  sports|(10000,[47,293,520,569,585,...|[0.2452264764527254,0.33698...|  1.0|       1.0|\n",
      "|business|(10000,[26,57,76,103,114,12...|[0.21088471936828349,0.4169...|  3.0|       1.0|\n",
      "|  sports|(10000,[15,70,161,186,195,2...|[0.19243354388454073,0.6804...|  1.0|       1.0|\n",
      "|  sports|(10000,[36,130,145,157,533,...|[0.16243186709011614,0.4579...|  1.0|       1.0|\n",
      "|  sports|(10000,[10,20,34,59,132,147...|[0.12633218377026162,0.8164...|  1.0|       1.0|\n",
      "|  sports|(10000,[76,77,141,204,262,3...|[0.10803912714356499,0.8309...|  1.0|       1.0|\n",
      "|  sports|(10000,[157,335,347,353,388...|[0.09473190813279275,0.6520...|  1.0|       1.0|\n",
      "|  sports|(10000,[1,24,63,87,121,126,...|[0.08359064308708228,0.8954...|  1.0|       1.0|\n",
      "|  sports|(10000,[307,367,373,375,456...|[0.07734678485393719,0.8125...|  1.0|       1.0|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"Category\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on Test data using Logistic Regression\n",
    "#### Keep in mind that the model has not seen the documents in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057057246712419"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of UNKNOWN Data using Logistic Regression\n",
    "#### Keep in mind that the model has not seen the documents in the Unknown data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|Category|                      features|                   probability|label|prediction|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|  sports|(10000,[1,15,94,147,356,585...|[0.231449591539279,0.492834...|  1.0|       1.0|\n",
      "|  sports|(10000,[45,157,288,293,468,...|[0.12872954468858455,0.5716...|  1.0|       1.0|\n",
      "|  sports|(10000,[59,63,147,150,157,1...|[0.11903603197440375,0.6733...|  1.0|       1.0|\n",
      "|  sports|(10000,[20,143,157,220,239,...|[0.11720490717896263,0.7137...|  1.0|       1.0|\n",
      "|  sports|(10000,[7,24,76,99,113,140,...|[0.11697998701478371,0.6641...|  1.0|       1.0|\n",
      "|  sports|(10000,[36,127,163,186,204,...|[0.09829173344749605,0.7605...|  1.0|       1.0|\n",
      "|  sports|(10000,[147,208,235,343,474...|[0.09773824375209174,0.7883...|  1.0|       1.0|\n",
      "|  sports|(10000,[20,120,147,161,177,...|[0.07440919158802979,0.8308...|  1.0|       1.0|\n",
      "|  sports|(10000,[76,148,204,211,233,...|[0.07308036310416878,0.8032...|  1.0|       1.0|\n",
      "|  sports|(10000,[62,147,208,235,312,...|[0.0641597466449879,0.86906...|  1.0|       1.0|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.918297808424174"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.transform(dfUN)\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"Category\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION USING \"NAIVE BAYES\"\n",
    "### RANDOM SPLIT DATA AGAIN\n",
    "### DEFINE PIPELINE\n",
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "(trainingData2, testData2) = df.randomSplit([0.8, 0.2], seed = 231279)\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "pipelinenb = Pipeline(stages=[regexTokenizer, remover, hashingTF, idf, label_stringIdx, nb])\n",
    "\n",
    "model = pipelinenb.fit(trainingData2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+----------+\n",
      "|               words|            features|label|         probability|prediction|\n",
      "+--------------------+--------------------+-----+--------------------+----------+\n",
      "|[10, treasures, u...|(10000,[2,93,126,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[100, years, afte...|(10000,[32,87,90,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[13, pop, rock, a...|(10000,[26,57,69,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[13, pop, rock, a...|(10000,[31,37,62,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[13, pop, rock, a...|(10000,[57,62,122...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[14, pop, rock, a...|(10000,[12,23,60,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[15, pop, rock, a...|(10000,[29,76,104...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[2018, n, f, l, d...|(10000,[33,87,123...|  1.0|   [0.0,1.0,0.0,0.0]|       1.0|\n",
      "|[28, years, after...|(10000,[65,104,12...|  2.0|[4.98052256750894...|       2.0|\n",
      "|[5, schoolhouse, ...|(10000,[8,15,16,1...|  2.0|[8.98667653514945...|       2.0|\n",
      "|[6, classical, mu...|(10000,[26,76,104...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[6, classical, mu...|(10000,[23,69,78,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[6, classical, mu...|(10000,[90,119,15...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[6, classical, mu...|(10000,[87,128,15...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[7, classical, mu...|(10000,[63,65,76,...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[7, classical, mu...|(10000,[1,63,65,1...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[8, classical, mu...|(10000,[1,24,47,5...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[8, classical, mu...|(10000,[167,210,2...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[8, classical, mu...|(10000,[43,126,14...|  2.0|   [0.0,0.0,1.0,0.0]|       2.0|\n",
      "|[a, battle, over,...|(10000,[1,58,63,7...|  3.0|   [0.0,0.0,0.0,1.0]|       3.0|\n",
      "+--------------------+--------------------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbdata = model.transform(trainingData).select(\"words\",\"features\",\"label\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Prediction of TEst Data using Model Trained on \"Naive Bayes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|Category|                      features|                   probability|label|prediction|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|  sports|(10000,[87,115,186,312,360,...|[1.0,4.5637026367223514E-20...|  1.0|       0.0|\n",
      "|    arts|(10000,[15,76,278,312,321,3...|[1.0,4.80191748543393E-31,2...|  2.0|       0.0|\n",
      "|  sports|(10000,[1,2,157,286,312,332...|[1.0,1.0338429046465282E-34...|  1.0|       0.0|\n",
      "|politics|(10000,[71,195,200,219,321,...|[1.0,1.1843904863324864E-46...|  0.0|       0.0|\n",
      "|politics|(10000,[26,52,63,65,76,78,1...|[1.0,4.443174102829313E-126...|  0.0|       0.0|\n",
      "|politics|(10000,[103,126,141,157,241...|[1.0,4.150040771021918E-174...|  0.0|       0.0|\n",
      "|politics|(10000,[8,15,21,44,52,68,12...|[1.0,2.96362269377377E-175,...|  0.0|       0.0|\n",
      "|    arts|(10000,[1,18,20,32,41,47,56...|[1.0,2.582302963410581E-175...|  2.0|       0.0|\n",
      "|politics|(10000,[1,18,48,50,76,77,78...|[1.0,4.0935830812781184E-17...|  0.0|       0.0|\n",
      "|politics|(10000,[48,63,133,159,180,2...|[1.0,7.507000207736014E-197...|  0.0|       0.0|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData2)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Category\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Test data Using \"Naive Bayes\"\n",
    "#### Keep in mind that the model has not seen the documents in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322248379320339"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluatornb = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluatornb.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of UNKNOWN data Using \"Naive Bayes\"\n",
    "#### Keep in mind that the model has not seen the documents in the Unknown data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|Category|                      features|                   probability|label|prediction|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|politics|(10000,[21,103,115,126,130,...|[1.0,1.7200949986592894E-11...|  0.0|       0.0|\n",
      "|politics|(10000,[78,165,207,216,273,...|[1.0,1.4737382399933485E-13...|  0.0|       0.0|\n",
      "|politics|(10000,[1,76,141,273,344,37...|[1.0,3.490530220472768E-207...|  0.0|       0.0|\n",
      "|politics|(10000,[15,17,95,137,157,17...|[1.0,7.759440053264402E-226...|  0.0|       0.0|\n",
      "|politics|(10000,[1,87,115,126,147,16...|[1.0,1.4165077832079794E-26...|  0.0|       0.0|\n",
      "|politics|(10000,[1,24,76,78,87,93,10...|[1.0,0.0,0.0,3.177223790333...|  0.0|       0.0|\n",
      "|politics|(10000,[10,47,132,207,221,2...|[1.0,0.0,0.0,2.580050456943...|  0.0|       0.0|\n",
      "|politics|(10000,[1,20,60,82,95,120,1...|             [1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|politics|(10000,[1,21,24,29,69,77,92...|             [1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "|politics|(10000,[15,103,157,161,253,...|             [1.0,0.0,0.0,0.0]|  0.0|       0.0|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9387861118473364"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.transform(dfUN)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Category\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "evaluatornb = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluatornb.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate ACCURACY using Cross Validation on Logistic Regression\n",
    "Spark MLlib provides for cross-validation for hyperparameter tuning. Cross-validation attempts to fit the underlying estimator with user-specified combinations of parameters, cross-evaluate the fitted models, and output the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481706183750974"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "#from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "pipelineCVLR = Pipeline(stages=[regexTokenizer, remover, hashingTF, idf, label_stringIdx,cv])\n",
    "cvModel = pipelineCVLR.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of UNKNOWN Data using CV with Logistic Regression\n",
    "#### Keep in mind that the model has not seen the documents in the Unknown data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796340896607091"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = cvModel.transform(dfUN)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION USING \"RANDOM FOREST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|Category|                      features|                   probability|label|prediction|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|politics|(10000,[22,67,70,74,87,93,1...|[0.6262811921483312,0.13496...|  0.0|       0.0|\n",
      "|politics|(10000,[1,15,24,43,70,72,87...|[0.625484320693428,0.157946...|  0.0|       0.0|\n",
      "|politics|(10000,[1,15,78,87,138,150,...|[0.6142314841489602,0.16987...|  0.0|       0.0|\n",
      "|politics|(10000,[44,47,126,132,137,1...|[0.6055520409583321,0.16298...|  0.0|       0.0|\n",
      "|politics|(10000,[15,20,26,45,70,76,8...|[0.5981348959983048,0.14785...|  0.0|       0.0|\n",
      "|politics|(10000,[15,87,126,132,145,1...|[0.579238978116515,0.167673...|  0.0|       0.0|\n",
      "|politics|(10000,[12,18,21,45,169,213...|[0.5747873623922527,0.14981...|  0.0|       0.0|\n",
      "|politics|(10000,[47,71,76,77,87,113,...|[0.5743978416685226,0.16819...|  0.0|       0.0|\n",
      "|politics|(10000,[56,90,126,132,141,1...|[0.5573135528769587,0.15281...|  0.0|       0.0|\n",
      "|politics|(10000,[1,2,24,69,71,95,130...|[0.5498266909652658,0.14691...|  0.0|       0.0|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "pipelineRF = Pipeline(stages=[regexTokenizer, remover, hashingTF, idf, label_stringIdx, rf])\n",
    "\n",
    "# Train model with Training Data\n",
    "rfModel = pipelineRF.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Category\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy  of Test Data using \"Random Forest\"\n",
    "#### Keep in mind that the model has not seen the documents in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061810402318066"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy  of UNKNOWN Data using \"Random Forest\"\n",
    "#### Keep in mind that the model has not seen the documents in the Unknown data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|Category|                      features|                   probability|label|prediction|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "|politics|(10000,[1,20,60,82,95,120,1...|[0.5919684996671557,0.13488...|  0.0|       0.0|\n",
      "|politics|(10000,[1,24,76,78,87,93,10...|[0.5458226461800758,0.13562...|  0.0|       0.0|\n",
      "|politics|(10000,[10,47,132,207,221,2...|[0.541972058349105,0.171282...|  0.0|       0.0|\n",
      "|politics|(10000,[1,21,24,29,69,77,92...|[0.524626965702046,0.167296...|  0.0|       0.0|\n",
      "|politics|(10000,[21,103,115,126,130,...|[0.5021602611456732,0.20419...|  0.0|       0.0|\n",
      "|politics|(10000,[15,103,157,161,253,...|[0.45473108742121454,0.2065...|  0.0|       0.0|\n",
      "|politics|(10000,[78,165,207,216,273,...|[0.44781224279846,0.2173283...|  0.0|       0.0|\n",
      "|politics|(10000,[1,87,115,126,147,16...|[0.42437671757453715,0.2296...|  0.0|       0.0|\n",
      "|politics|(10000,[1,76,141,273,344,37...|[0.4107146215801406,0.21528...|  0.0|       0.0|\n",
      "|politics|(10000,[18,36,62,81,87,107,...|[0.3550010897441235,0.27851...|  0.0|       0.0|\n",
      "+--------+------------------------------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8011736273456751"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rfModel.transform(dfUN)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"Category\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSESSMENT:\n",
    "**(This analysis was intended to illustrate how to use the spark.ml machine learning package utilizing a machine learning pipeline on Data from a Public Resource like NY Times.)\n",
    "\n",
    "#### The Program also shows the accuracy of the learning Model by Calculating the Accuracy of Unknown dataset (Data which has not been used in Training or Test Dataset)\n",
    "\n",
    "\n",
    "#### Accuracy of Unknown Dataset on Various Models:\n",
    "##### Logistic Regression: $0.918297808424174$\n",
    "##### Naive Bayes : $0.9387861118473364$\n",
    "##### Cross Validation Using Logistic Regression : $0.9796340896607091$\n",
    "##### Random Forest : $0.8011736273456751$\n",
    "\n",
    "#### Clearly the Cross Validation yeilds highest accuracy.\n",
    "#### Random forest is not a good choice for high-dimensional sparse data.\n",
    "\n",
    "### Conclusion: Logistic Regression Using Cross Validation is the best model in our analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------------------------------------------------###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "##### https://www.youtube.com/watch?v=OednhGRp938&feature=youtu.be\n",
    "##### https://yidatao.github.io/2016-03-23/Document-Classification-using-pyspark/\n",
    "##### https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35\n",
    "##### https://www.youtube.com/watch?v=YX1xxWVxM0w\n",
    "##### https://ibm.ent.box.com/s/spcj7f3uz6qetq8442mnvw5j264wbilj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
